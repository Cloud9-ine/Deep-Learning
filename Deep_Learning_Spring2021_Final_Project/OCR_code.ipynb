{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ocr_kaggle.ipynb","provenance":[],"collapsed_sections":["D8jA6lrQdCuy","1t0XfJ5G-bmR","vlClZqQhiar8","GwhAuRhlySN6","_aKcQo76ioO3","4hDvpSTmzs1t","_VzmQqI7cinF","24didZZ3HFef"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"D8jA6lrQdCuy"},"source":["# **Imports & supporting functions**"]},{"cell_type":"code","metadata":{"id":"KBgAV-Z5UFek","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620417583163,"user_tz":-480,"elapsed":3034,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}},"outputId":"ff937de2-502f-45bb-e68c-e3caa2abceb9"},"source":["import sys\n","import os\n","import json\n","from skimage import io\n","import numpy as np\n","import time\n","\n","import torch\n","from torch import optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","!pip install utils\n","\n","## Mount Google Drive Data (If using Google Colaboratory)\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","except:\n","    print(\"Mounting Failed.\")\n","\n","py_file_dir = '/content/drive/MyDrive/Colab Notebooks/project/'\n","sys.path.append(py_file_dir)\n","!ls '/content/drive/MyDrive/Colab Notebooks/project/'"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: utils in /usr/local/lib/python3.7/dist-packages (1.0.1)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","attr_dict.py  __init__.py\t mynn.py       __pycache__\n","config.py     misc.py\t\t myutils.py    rmi.py\n","hrnetv2.py    model_trained.pth  ocr_utils.py  rmi_utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wMNAaMF6sK65","executionInfo":{"status":"ok","timestamp":1620417583164,"user_tz":-480,"elapsed":3029,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["from myutils import get_trunk\n","from mynn import initialize_weights, Upsample, scale_as\n","from mynn import ResizeX\n","from myutils import get_trunk\n","from myutils import BNReLU, get_aspp\n","from myutils import make_attn_head\n","from ocr_utils import SpatialGather_Module, SpatialOCR_Module\n","from config import cfg\n","from rmi import RMILoss\n","\n","def fmt_scale(prefix, scale):\n","    \"\"\"\n","    format scale name\n","\n","    :prefix: a string that is the beginning of the field name\n","    :scale: a scale value (0.25, 0.5, 1.0, 2.0)\n","    \"\"\"\n","\n","    scale_str = str(float(scale))\n","    scale_str.replace('.', '')\n","    return f'{prefix}_{scale_str}x'"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1t0XfJ5G-bmR"},"source":["# **Network archtecture**\n"]},{"cell_type":"code","metadata":{"id":"Oe1FLFBW-bCq","executionInfo":{"status":"ok","timestamp":1620417586737,"user_tz":-480,"elapsed":652,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["class OCR_block(nn.Module):\n","    \"\"\"\n","    Some of the code in this class is borrowed from:\n","    https://github.com/HRNet/HRNet-Semantic-Segmentation/tree/HRNet-OCR\n","    \"\"\"\n","    def __init__(self, high_level_ch):\n","        super(OCR_block, self).__init__()\n","\n","        ocr_mid_channels = cfg.MODEL.OCR.MID_CHANNELS\n","        ocr_key_channels = cfg.MODEL.OCR.KEY_CHANNELS\n","        #num_classes = cfg.DATASET.NUM_CLASSES\n","        num_classes = 2\n","        \n","        self.conv3x3_ocr = nn.Sequential(\n","            nn.Conv2d(high_level_ch, ocr_mid_channels,\n","                      kernel_size=3, stride=1, padding=1),\n","            BNReLU(ocr_mid_channels),\n","        )\n","        self.ocr_gather_head = SpatialGather_Module(num_classes)\n","        print('X')\n","        self.ocr_distri_head = SpatialOCR_Module(in_channels=ocr_mid_channels,\n","                                                 key_channels=ocr_key_channels,\n","                                                 out_channels=ocr_mid_channels,\n","                                                 scale=1,\n","                                                 dropout=0.05,\n","                                                 )\n","        self.cls_head = nn.Conv2d(\n","            ocr_mid_channels, num_classes, kernel_size=1, stride=1, padding=0,\n","            bias=True)\n","        \n","        self.aux_head = nn.Sequential(\n","            nn.Conv2d(high_level_ch, high_level_ch,\n","                      kernel_size=1, stride=1, padding=0),\n","            BNReLU(high_level_ch),\n","            nn.Conv2d(high_level_ch, num_classes,\n","                      kernel_size=1, stride=1, padding=0, bias=True)\n","        )\n","\n","        if cfg.OPTIONS.INIT_DECODER:\n","            initialize_weights(self.conv3x3_ocr,\n","                               self.ocr_gather_head,\n","                               self.ocr_distri_head,\n","                               self.cls_head,\n","                               self.aux_head)\n","\n","    def forward(self, high_level_features):\n","        feats = self.conv3x3_ocr(high_level_features)\n","        aux_out = self.aux_head(high_level_features)\n","        context = self.ocr_gather_head(feats, aux_out)\n","        ocr_feats = self.ocr_distri_head(feats, context)\n","        cls_out = self.cls_head(ocr_feats)\n","        return cls_out, aux_out, ocr_feats\n","\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vvafs4UvvS15","executionInfo":{"status":"ok","timestamp":1620417587487,"user_tz":-480,"elapsed":1397,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["class MscaleOCR(nn.Module):\n","    \"\"\"\n","    OCR net\n","    \"\"\"\n","    def __init__(self, num_classes, trunk='hrnetv2', criterion=None):\n","        super(MscaleOCR, self).__init__()\n","        self.criterion = criterion\n","        self.backbone, _, _, high_level_ch = get_trunk(trunk)\n","        # print(self.backbone.conv1)\n","        self.backbone.conv1 = nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.ocr = OCR_block(high_level_ch)\n","        self.scale_attn = make_attn_head(\n","            in_ch=cfg.MODEL.OCR.MID_CHANNELS, out_ch=1)\n","\n","\n","    def _fwd(self, x):\n","        x_size = x.size()[2:]\n","\n","        _, _, high_level_features = self.backbone(x)\n","        cls_out, aux_out, ocr_mid_feats = self.ocr(high_level_features)\n","        attn = self.scale_attn(ocr_mid_feats)\n","\n","        aux_out = Upsample(aux_out, x_size)\n","        cls_out = Upsample(cls_out, x_size)\n","        attn = Upsample(attn, x_size)\n","\n","        return {'cls_out': cls_out,\n","                'aux_out': aux_out,\n","                'logit_attn': attn}\n","\n","    def nscale_forward(self, inputs, scales):\n","        \"\"\"\n","        Hierarchical attention, primarily used for getting best inference\n","        results.\n","        We use attention at multiple scales, giving priority to the lower\n","        resolutions. For example, if we have 4 scales {0.5, 1.0, 1.5, 2.0},\n","        then evaluation is done as follows:\n","              p_joint = attn_1.5 * p_1.5 + (1 - attn_1.5) * down(p_2.0)\n","              p_joint = attn_1.0 * p_1.0 + (1 - attn_1.0) * down(p_joint)\n","              p_joint = up(attn_0.5 * p_0.5) * (1 - up(attn_0.5)) * p_joint\n","        The target scale is always 1.0, and 1.0 is expected to be part of the\n","        list of scales. When predictions are done at greater than 1.0 scale,\n","        the predictions are downsampled before combining with the next lower\n","        scale.\n","        Inputs:\n","          scales - a list of scales to evaluate\n","          inputs - dict containing 'images', the input, and 'gts', the ground\n","                   truth mask\n","        Output:\n","          If training, return loss, else return prediction + attention\n","        \"\"\"\n","        x_1x = inputs['images']\n","\n","        assert 1.0 in scales, 'expected 1.0 to be the target scale'\n","        # Lower resolution provides attention for higher rez predictions,\n","        # so we evaluate in order: high to low\n","        scales = sorted(scales, reverse=True)\n","\n","        pred = None\n","        aux = None\n","        output_dict = {}\n","\n","        for s in scales:\n","            x = ResizeX(x_1x, s)\n","            outs = self._fwd(x)\n","            cls_out = outs['cls_out']\n","            attn_out = outs['logit_attn']\n","            aux_out = outs['aux_out']\n","\n","            output_dict[fmt_scale('pred', s)] = cls_out\n","            if s != 2.0:\n","                output_dict[fmt_scale('attn', s)] = attn_out\n","\n","            if pred is None:\n","                pred = cls_out\n","                aux = aux_out\n","            elif s >= 1.0:\n","                # downscale previous\n","                pred = scale_as(pred, cls_out)\n","                pred = attn_out * cls_out + (1 - attn_out) * pred\n","                aux = scale_as(aux, cls_out)\n","                aux = attn_out * aux_out + (1 - attn_out) * aux\n","            else:\n","                # s < 1.0: upscale current\n","                cls_out = attn_out * cls_out\n","                aux_out = attn_out * aux_out\n","\n","                cls_out = scale_as(cls_out, pred)\n","                aux_out = scale_as(aux_out, pred)\n","                attn_out = scale_as(attn_out, pred)\n","\n","                pred = cls_out + (1 - attn_out) * pred\n","                aux = aux_out + (1 - attn_out) * aux\n","\n","        if self.training:\n","            assert 'gts' in inputs\n","            gts = inputs['gts']\n","            loss = cfg.LOSS.OCR_ALPHA * self.criterion(aux, gts) + \\\n","                self.criterion(pred, gts)\n","            return loss\n","        else:\n","            output_dict['pred'] = pred\n","            return output_dict\n","\n","    def two_scale_forward(self, inputs):\n","        \"\"\"\n","        Do we supervised both aux outputs, lo and high scale?\n","        Should attention be used to combine the aux output?\n","        Normally we only supervise the combined 1x output\n","        If we use attention to combine the aux outputs, then\n","        we can use normal weighting for aux vs. cls outputs\n","        \"\"\"\n","        assert 'images' in inputs\n","        x_1x = inputs['images']\n","\n","        x_lo = ResizeX(x_1x, cfg.MODEL.MSCALE_LO_SCALE)\n","        lo_outs = self._fwd(x_lo)\n","        pred_05x = lo_outs['cls_out']\n","        p_lo = pred_05x\n","        aux_lo = lo_outs['aux_out']\n","        logit_attn = lo_outs['logit_attn']\n","        attn_05x = logit_attn\n","\n","        hi_outs = self._fwd(x_1x)\n","        pred_10x = hi_outs['cls_out']\n","        p_1x = pred_10x\n","        aux_1x = hi_outs['aux_out']\n","\n","        p_lo = logit_attn * p_lo\n","        aux_lo = logit_attn * aux_lo\n","        p_lo = scale_as(p_lo, p_1x)\n","        aux_lo = scale_as(aux_lo, p_1x)\n","\n","        logit_attn = scale_as(logit_attn, p_1x)\n","\n","        # combine lo and hi predictions with attention\n","        joint_pred = p_lo + (1 - logit_attn) * p_1x\n","        joint_aux = aux_lo + (1 - logit_attn) * aux_1x\n","        #print(self.training)\n","        if self.training:\n","            gts = inputs['gts']\n","            do_rmi = cfg.LOSS.OCR_AUX_RMI\n","            aux_loss = self.criterion(joint_aux, gts)\n","            #print(aux_loss)\n","            # Optionally turn off RMI loss for first epoch to try to work\n","            # around cholesky errors of singular matrix\n","            #do_rmi_main = True  # cfg.EPOCH > 0\n","            main_loss = self.criterion(joint_pred, gts)\n","            loss = cfg.LOSS.OCR_ALPHA * aux_loss + main_loss\n","\n","            # Optionally, apply supervision to the multi-scale predictions\n","            # directly. Turn off RMI to keep things lightweight\n","            if cfg.LOSS.SUPERVISED_MSCALE_WT:\n","                scaled_pred_05x = scale_as(pred_05x, p_1x)\n","                loss_lo = self.criterion(scaled_pred_05x, gts)\n","                loss_hi = self.criterion(pred_10x, gts)\n","                loss += cfg.LOSS.SUPERVISED_MSCALE_WT * loss_lo\n","                loss += cfg.LOSS.SUPERVISED_MSCALE_WT * loss_hi\n","            return loss, joint_pred\n","        else:\n","            output_dict = {\n","                'pred': joint_pred,\n","                'pred_05x': pred_05x,\n","                'pred_10x': pred_10x,\n","                'attn_05x': attn_05x,\n","            }\n","            return output_dict\n","\n","    def forward(self, inputs):\n","        \n","        if cfg.MODEL.N_SCALES and not self.training:\n","            return self.nscale_forward(inputs, cfg.MODEL.N_SCALES)\n","\n","        return self.two_scale_forward(inputs)\n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"3k2aZyToBWpN","executionInfo":{"status":"ok","timestamp":1620417587488,"user_tz":-480,"elapsed":1395,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["def HRNet_Mscale(num_classes, criterion):\n","    return MscaleOCR(num_classes, trunk='hrnetv2', criterion=criterion)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vlClZqQhiar8"},"source":["# **Data Loader**\n"]},{"cell_type":"code","metadata":{"id":"ZvsMO1knihA_","executionInfo":{"status":"ok","timestamp":1620417589305,"user_tz":-480,"elapsed":732,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["# Data Directory \n","data_dir = \"./drive/MyDrive/Colab Notebooks/\"\n","# train_dir = \"./drive/MyDrive/Colab Notebooks/stage1_train/\"\n","# test_dir = \"./drive/MyDrive/Colab Notebooks/stage1_test/\"\n","mask_json = \"./drive/MyDrive/Colab Notebooks/map.json\""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"L5lzzcUUifBr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620417589306,"user_tz":-480,"elapsed":729,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}},"outputId":"ebe5de27-b1bb-45cb-bfba-6c43161b84f5"},"source":["## Image Transforms\n","img_transform = transforms.Compose([\n","    # transforms.ToPILImage(),\n","    transforms.Scale(256),\n","    transforms.CenterCrop((256, 256)),\n","    transforms.ToTensor()\n","])\n","\n","## Image Dataloader\n","class ImageDataset(Dataset):\n","    \"\"\"\n","    ImageDataset\n","    \"\"\"\n","    def __init__(self, input_dir, op, mask_json_path, transforms=img_transform):\n","        \"\"\"\n","        Args:\n","            input_dir (str): Path to either colorization or segmentation directory\n","            op (str): One of \"train\", \"val\", or \"test\" signifying the desired split\n","            mask_json_path (str): Path to mapping.json file\n","            transforms (list or None): Image transformations to apply upon loading.\n","        \"\"\"\n","        self.transform = transforms\n","        self.op = op\n","        with open(mask_json_path, 'r') as f:\n","            self.mask = json.load(f)\n","        self.mask_num = len(self.mask)  # There are 2 categories: \n","        self.mask_value = [value for value in self.mask.values()]\n","        self.mask_value.sort()\n","        try:\n","            if self.op == 'train':\n","                self.data_dir = os.path.join(input_dir, \"stage1_train\")\n","            elif self.op == 'test':\n","                self.data_dir = os.path.join(input_dir, \"stage1_test\")\n","        except ValueError:\n","            print('op should be either train or test!')\n","\n","    def __len__(self):\n","        return len(next(os.walk(self.data_dir))[1])\n","\n","    def __getitem__(self, idx):\n","        ## Load Image and Parse Properties\n","\n","        img_name = \"images/\" + str(idx) + \".png\"\n","        mask_name = \"masks/\" + str(idx) + \".png\"\n","        img = io.imread(os.path.join(self.data_dir, str(idx), img_name))\n","        mask = io.imread(os.path.join(self.data_dir, str(idx), mask_name))\n","        if len(mask.shape) == 2:\n","              h, w = mask.shape\n","        elif len(mask.shape) == 3:\n","              h, w, c = mask.shape\n","          ## Convert grey-scale label to one-hot encoding\n","        new_mask = np.zeros((h, w, self.mask_num))\n","       \n","        for idx in range(self.mask_num):\n","              # if the mask has 3 dimension use this code\n","              new_mask[:, :, idx] = mask[:, :, 0] == self.mask_value[idx]\n","              # if the mask has 1 dimension use the code below\n","              # new_mask[:, :, idx] = mask == self.mask_value[idx]\n","\n","        img = transforms.ToPILImage()(img)\n","        new_mask = new_mask.astype(np.uint8)\n","        new_mask = transforms.ToPILImage()(new_mask)\n","        if self.transform:\n","              img, mask = self.image_transform(img, new_mask)\n","        \n","        return img, mask\n","\n","    def image_transform(self, img, mask):\n","        ## Apply Transformations to Image and Mask\n","        img = img_transform(img)\n","        mask = img_transform(mask)\n","        return img, mask"],"execution_count":31,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:285: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n","  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"GwhAuRhlySN6"},"source":["# **Init for loss**"]},{"cell_type":"code","metadata":{"id":"AfizFFTDyRFl","executionInfo":{"status":"ok","timestamp":1620425214305,"user_tz":-480,"elapsed":955,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["class AverageMeter(object):\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def dice_score_image(prediction, target, n_classes):\n","    '''\n","      computer the mean dice score for a single image\n","\n","      Reminders: A false positive is a result that indicates a given condition exists, when it does not\n","               A false negative is a test result that indicates that a condition does not hold, while in fact it does\n","      Args:\n","          prediction (tensor): predictied labels of the image\n","          target (tensor): ground truth of the image\n","          n_classes (int): number of classes\n","    \n","      Returns:\n","          m_dice (float): Mean dice score over classes\n","    '''\n","    ## Should test image one by one\n","    # assert img.shape[0] == 1 #This line can not be deleted\n","    ## TODO: Compute Dice Score for Each Class. Compute Mean Dice Score over Classes.\n","    # prediction, torch.Size([256, 320])\n","    # target, torch.Size([6, 256, 320]), one-hot encoding \n","    # 6 classes: 0, 32, 64, 96, 128, 224\n","    smooth = 1\n","    size = prediction.size(0) * prediction.size(1)\n","    pred = prediction\n","    pred_flat = pred.view(-1, size)\n","    if torch.cuda.is_available():\n","      # torch.cuda.empty_cache()\n","      pred_flat = pred_flat.cpu()\n","    pred_flat = pred_flat.detach().numpy()\n","    dice_classes = np.zeros(n_classes)\n","    for cl in range(n_classes):\n","        cls = target[cl]\n","        cls_flat = cls.view(-1, size)\n","        if torch.cuda.is_available():\n","          cls_flat = cls_flat.cpu()\n","        cls_flat = cls_flat.detach().numpy()\n","        TP = 0\n","        FP = 0\n","        FN = 0\n","        TN = 0\n","        for i in range(size):\n","          if cls_flat[0][i] == 1 and pred_flat[0][i] == cl:\n","            TP += 1\n","          elif cls_flat[0][i] == 0 and pred_flat[0][i] == cl:\n","            FP += 1\n","          elif cls_flat[0][i] == 1 and pred_flat[0][i] != cl:\n","            FN += 1\n","          else:\n","            TN += 1\n","        #When there is no grount truth of the class in this image\n","        #Give 1 dice score if False Positive pixel number is 0, \n","        #give 0 dice score if False Positive pixel number is not 0 (> 0).\n","        if (TP + FN == 0):\n","          if FP == 0:\n","            dice_classes[cl] = 1\n","          else:\n","            dice_classes[cl] = 0\n","        else:\n","          dice_classes[cl] = 2 * TP / (2 * TP + FP + FN) \n","    return dice_classes.mean()\n","\n","\n","def dice_score_dataset(model, dataloader, num_classes, use_gpu=True):\n","    \"\"\"\n","    Compute the mean dice score on a set of data.\n","    \n","    Note that multiclass dice score can be defined as the mean over classes of binary\n","    dice score. Dice score is computed per image. Mean dice score over the dataset is the dice\n","    score averaged across all images.\n","    \n","    Reminders: A false positive is a result that indicates a given condition exists, when it does not\n","               A false negative is a test result that indicates that a condition does not hold, while in fact it does\n","     \n","    Args:\n","        model (UNET class): Your trained model\n","        dataloader (DataLoader): Dataset for evaluation\n","        num_classes (int): Number of classes\n","    \n","    Returns:\n","        m_dice (float): Mean dice score over the input dataset\n","    \"\"\"\n","    ## Number of Batches and Cache over Dataset \n","    n_batches = len(dataloader)\n","    scores = np.zeros(n_batches)\n","    ## Evaluate\n","    #model.eval()\n","    idx = 0\n","    for data in dataloader:\n","        ## Format Data\n","        start_time = time.time()\n","        with torch.no_grad():\n","          img, target = data\n","          if use_gpu:\n","              images = img.cuda()\n","              gts = target.cuda()\n","          ## Make Predictions\n","          inputs = {'images': images, 'gts': gts}\n","          loss, out = model(inputs)\n","          prediction = torch.argmax(out, dim = 1)\n","          batch_size = prediction.shape[0]\n","          for i in range(batch_size):\n","            scores[idx] += dice_score_image(prediction[i], target[i], 2)\n","          scores[idx] /= batch_size\n","          idx += 1\n","        end_time = time.time()\n","    ## Average Dice Score Over Images\n","        #print('time takes for images eval: ', end_time - start_time)\n","    m_dice = scores.mean()\n","    return m_dice\n","\n","\n","class BinaryDICELoss(nn.Module):\n","    def __init__(self):\n","      super(BinaryDICELoss, self).__init__()\n","      \n","    def forward(self, pred, target):\n","      # pred: (N H W)\n","      # target: (N H W)\n","      smooth = 1\n","      batch_size = target.shape[0]\n","      loss = 0\n","      pred_flat = pred.view(batch_size, -1)\n","      target_flat = target.view(batch_size, -1)\n","      dice_score = (2 * ((pred_flat * target_flat).sum()) + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n","      loss = (1 - dice_score) / batch_size\n","      return loss\n","\n","\n","# TODO: Implement DICE loss, \n","# It should conform to how we computer the dice score.\n","class DICELoss(nn.Module):\n","    def __init__(self):\n","      super(DICELoss, self).__init__()\n","      \n","    def forward(self, pred, target):\n","      # pred: (N C H W)\n","      # target: (N C H W), one-hot already\n","      smooth = 1\n","      batch_size = target.shape[0]\n","      n_classes = target.shape[1]\n","      criterion = BinaryDICELoss()\n","      loss = 0\n","      for i in range(n_classes):\n","        # pred, target from (N C H W) into (N H W)\n","        loss += criterion(pred[:,i], target[:,i])\n","      loss /= n_classes\n","      return loss"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODbyNGjTSAgU","executionInfo":{"status":"ok","timestamp":1620417590717,"user_tz":-480,"elapsed":718,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["class CrossEntropyLoss2d(nn.Module):\n","    \"\"\"\n","    Cross Entroply NLL Loss\n","    \"\"\"\n","\n","    def __init__(self, weight=None, ignore_index=cfg.DATASET.IGNORE_LABEL,\n","                 reduction='mean'):\n","        super(CrossEntropyLoss2d, self).__init__()\n","        self.nll_loss = nn.NLLLoss(weight, reduction=reduction,\n","                                   ignore_index=ignore_index)\n","\n","    def forward(self, inputs, targets, do_rmi=None):\n","        #inputs = inputs.to(dtype=torch.long)\n","        targets = torch.argmax(targets, dim=1)\n","        return self.nll_loss(F.log_softmax(inputs, dim=1), targets)"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_aKcQo76ioO3"},"source":["# **Training function**"]},{"cell_type":"code","metadata":{"id":"X8HXmQZNxmk-","executionInfo":{"status":"ok","timestamp":1620417592999,"user_tz":-480,"elapsed":1019,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["def train(train_loader, net, optim, curr_epoch):\n","    \"\"\"\n","    Runs the training loop per epoch\n","    train_loader: Data loader for train\n","    net: thet network\n","    optimizer: optimizer\n","    curr_epoch: current epoch\n","    return:\n","    \"\"\"\n","    net.train()\n","    train_main_loss = AverageMeter()\n","    print(\"Training...\")\n","    for i, data in enumerate(train_loader):\n","        print(\"Loading...\")\n","        images, gts = data\n","        if i == 0:\n","          input_save = images\n","          gts_save = gts\n","        batch_pixel_size = images.size(0) * images.size(2) * images.size(3)\n","        images, gts= images.cuda(), gts.cuda()\n","        inputs = {'images': images, 'gts': gts}\n","\n","        optim.zero_grad()\n","        main_loss, output = net(inputs)\n","        main_loss = main_loss.mean()\n","        log_main_loss = main_loss.clone().detach_()\n","\n","        train_main_loss.update(log_main_loss.item(), batch_pixel_size)\n","\n","        main_loss.backward()\n","\n","        optim.step()\n","\n","        msg = ('[epoch {}], [iter {} / {}], [train main loss {:0.6f}],'\n","               ' [lr {:0.6f}]')\n","        msg = msg.format(\n","            curr_epoch, i + 1, len(train_loader), train_main_loss.avg,\n","            optim.param_groups[-1]['lr'])\n","        print(msg)\n"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4hDvpSTmzs1t"},"source":["# **Training & Accuracy**"]},{"cell_type":"code","metadata":{"id":"RLYDWg-Eis10","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1620424420873,"user_tz":-480,"elapsed":6821073,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}},"outputId":"b3ce3db8-b8c9-4087-e225-31a82b9284fc"},"source":["torch.cuda.empty_cache()\n","num_classes = 2\n","NUM_EPOCH = 100\n","criterion = CrossEntropyLoss2d()\n","#criterion =  RMILoss(num_classes=2, ignore_index=cfg.DATASET.IGNORE_LABEL).cuda()\n","#criterion =  DICELoss()\n","\n","net = HRNet_Mscale(num_classes, criterion)\n","net.cuda()\n","# print(net)\n","\n","i = 0\n","train_main_loss = 0\n","optimizer = optim.Adam(net.parameters(),lr=0.001,weight_decay=0, amsgrad=False)\n","#optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.09)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n","\n","\n","train_dataset = ImageDataset(input_dir=data_dir, op=\"train\", mask_json_path=mask_json)\n","train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False)\n","\n","test_dataset = ImageDataset(input_dir=data_dir, op=\"test\", mask_json_path=mask_json)\n","test_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False)\n","# print(torch.__version__)\n","\n","for epoch in range(NUM_EPOCH):\n","\n","  train(train_dataloader, net, optimizer, epoch)\n","  scheduler.step()"],"execution_count":35,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 71 / 168], [train main loss 0.089998], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 72 / 168], [train main loss 0.090669], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 73 / 168], [train main loss 0.090354], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 74 / 168], [train main loss 0.090486], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 75 / 168], [train main loss 0.090766], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 76 / 168], [train main loss 0.090452], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 77 / 168], [train main loss 0.090966], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 78 / 168], [train main loss 0.090880], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 79 / 168], [train main loss 0.090503], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 80 / 168], [train main loss 0.090289], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 81 / 168], [train main loss 0.091022], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 82 / 168], [train main loss 0.090914], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 83 / 168], [train main loss 0.090315], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 84 / 168], [train main loss 0.092058], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 85 / 168], [train main loss 0.092490], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 86 / 168], [train main loss 0.092297], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 87 / 168], [train main loss 0.092136], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 88 / 168], [train main loss 0.091410], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 89 / 168], [train main loss 0.091451], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 90 / 168], [train main loss 0.091594], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 91 / 168], [train main loss 0.090802], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 92 / 168], [train main loss 0.090387], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 93 / 168], [train main loss 0.089816], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 94 / 168], [train main loss 0.089408], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 95 / 168], [train main loss 0.089776], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 96 / 168], [train main loss 0.089507], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 97 / 168], [train main loss 0.089081], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 98 / 168], [train main loss 0.089442], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 99 / 168], [train main loss 0.089727], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 100 / 168], [train main loss 0.089283], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 101 / 168], [train main loss 0.089679], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 102 / 168], [train main loss 0.089333], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 103 / 168], [train main loss 0.089268], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 104 / 168], [train main loss 0.089204], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 105 / 168], [train main loss 0.089185], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 106 / 168], [train main loss 0.089072], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 107 / 168], [train main loss 0.089588], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 108 / 168], [train main loss 0.089200], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 109 / 168], [train main loss 0.089199], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 110 / 168], [train main loss 0.088938], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 111 / 168], [train main loss 0.089213], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 112 / 168], [train main loss 0.089621], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 113 / 168], [train main loss 0.089483], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 114 / 168], [train main loss 0.089453], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 115 / 168], [train main loss 0.090514], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 116 / 168], [train main loss 0.090264], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 117 / 168], [train main loss 0.089742], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 118 / 168], [train main loss 0.089802], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 119 / 168], [train main loss 0.089825], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 120 / 168], [train main loss 0.089263], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 121 / 168], [train main loss 0.088903], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 122 / 168], [train main loss 0.088499], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 123 / 168], [train main loss 0.088029], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 124 / 168], [train main loss 0.087785], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 125 / 168], [train main loss 0.087703], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 126 / 168], [train main loss 0.087461], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 127 / 168], [train main loss 0.087356], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 128 / 168], [train main loss 0.087618], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 129 / 168], [train main loss 0.087490], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 130 / 168], [train main loss 0.087389], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 131 / 168], [train main loss 0.087388], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 132 / 168], [train main loss 0.087689], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 133 / 168], [train main loss 0.087609], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 134 / 168], [train main loss 0.087335], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 135 / 168], [train main loss 0.087905], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 136 / 168], [train main loss 0.087820], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 137 / 168], [train main loss 0.087573], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 138 / 168], [train main loss 0.087192], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 139 / 168], [train main loss 0.086900], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 140 / 168], [train main loss 0.086491], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 141 / 168], [train main loss 0.086582], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 142 / 168], [train main loss 0.086233], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 143 / 168], [train main loss 0.086045], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 144 / 168], [train main loss 0.085813], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 145 / 168], [train main loss 0.085842], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 146 / 168], [train main loss 0.085677], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 147 / 168], [train main loss 0.085394], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 148 / 168], [train main loss 0.085241], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 149 / 168], [train main loss 0.085630], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 150 / 168], [train main loss 0.085749], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 151 / 168], [train main loss 0.085330], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 152 / 168], [train main loss 0.085334], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 153 / 168], [train main loss 0.085294], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 154 / 168], [train main loss 0.085531], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 155 / 168], [train main loss 0.085261], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 156 / 168], [train main loss 0.085627], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 157 / 168], [train main loss 0.085928], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 158 / 168], [train main loss 0.085638], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 159 / 168], [train main loss 0.085676], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 160 / 168], [train main loss 0.085433], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 161 / 168], [train main loss 0.085266], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 162 / 168], [train main loss 0.085533], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 163 / 168], [train main loss 0.085262], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 164 / 168], [train main loss 0.085287], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 165 / 168], [train main loss 0.085037], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 166 / 168], [train main loss 0.085366], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 167 / 168], [train main loss 0.085001], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 31], [iter 168 / 168], [train main loss 0.084885], [lr 0.001000]\n","Training...\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 1 / 168], [train main loss 0.152274], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 2 / 168], [train main loss 0.113327], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 3 / 168], [train main loss 0.097210], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 4 / 168], [train main loss 0.088669], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 5 / 168], [train main loss 0.078042], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 6 / 168], [train main loss 0.079348], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 7 / 168], [train main loss 0.075194], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 8 / 168], [train main loss 0.068485], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 9 / 168], [train main loss 0.077139], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 10 / 168], [train main loss 0.098689], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 11 / 168], [train main loss 0.103129], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 12 / 168], [train main loss 0.101017], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 13 / 168], [train main loss 0.097887], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 14 / 168], [train main loss 0.101791], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 15 / 168], [train main loss 0.101348], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 16 / 168], [train main loss 0.099326], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 17 / 168], [train main loss 0.098739], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 18 / 168], [train main loss 0.096625], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 19 / 168], [train main loss 0.094841], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 20 / 168], [train main loss 0.091059], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 21 / 168], [train main loss 0.090731], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 22 / 168], [train main loss 0.089651], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 23 / 168], [train main loss 0.088435], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 24 / 168], [train main loss 0.086616], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 25 / 168], [train main loss 0.086528], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 26 / 168], [train main loss 0.089116], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 27 / 168], [train main loss 0.087282], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 28 / 168], [train main loss 0.087356], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 29 / 168], [train main loss 0.086021], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 30 / 168], [train main loss 0.085775], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 31 / 168], [train main loss 0.084336], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 32 / 168], [train main loss 0.084376], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 33 / 168], [train main loss 0.085580], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 34 / 168], [train main loss 0.084800], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 35 / 168], [train main loss 0.084757], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 36 / 168], [train main loss 0.084501], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 37 / 168], [train main loss 0.084351], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 38 / 168], [train main loss 0.085215], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 39 / 168], [train main loss 0.085057], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 40 / 168], [train main loss 0.085259], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 41 / 168], [train main loss 0.085104], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 42 / 168], [train main loss 0.085542], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 43 / 168], [train main loss 0.085062], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 44 / 168], [train main loss 0.084376], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 45 / 168], [train main loss 0.085411], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 46 / 168], [train main loss 0.084865], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 47 / 168], [train main loss 0.085678], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 48 / 168], [train main loss 0.085818], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 49 / 168], [train main loss 0.084721], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 50 / 168], [train main loss 0.084339], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 51 / 168], [train main loss 0.084359], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 52 / 168], [train main loss 0.084940], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 53 / 168], [train main loss 0.085041], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 54 / 168], [train main loss 0.084975], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 55 / 168], [train main loss 0.084123], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 56 / 168], [train main loss 0.084931], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 57 / 168], [train main loss 0.085041], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 58 / 168], [train main loss 0.084329], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 59 / 168], [train main loss 0.083704], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 60 / 168], [train main loss 0.085088], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 61 / 168], [train main loss 0.085291], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 62 / 168], [train main loss 0.085647], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 63 / 168], [train main loss 0.085290], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 64 / 168], [train main loss 0.085135], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 65 / 168], [train main loss 0.085924], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 66 / 168], [train main loss 0.085825], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 67 / 168], [train main loss 0.084957], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 68 / 168], [train main loss 0.085375], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 69 / 168], [train main loss 0.084905], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 70 / 168], [train main loss 0.085544], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 71 / 168], [train main loss 0.085089], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 72 / 168], [train main loss 0.085568], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 73 / 168], [train main loss 0.085199], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 74 / 168], [train main loss 0.085021], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 75 / 168], [train main loss 0.085248], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 76 / 168], [train main loss 0.084915], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 77 / 168], [train main loss 0.085368], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 78 / 168], [train main loss 0.085178], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 79 / 168], [train main loss 0.084763], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 80 / 168], [train main loss 0.084490], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 81 / 168], [train main loss 0.085229], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 82 / 168], [train main loss 0.084993], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 83 / 168], [train main loss 0.084328], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 84 / 168], [train main loss 0.086115], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 85 / 168], [train main loss 0.086473], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 86 / 168], [train main loss 0.086333], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 87 / 168], [train main loss 0.086084], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 88 / 168], [train main loss 0.085412], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 89 / 168], [train main loss 0.085305], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 90 / 168], [train main loss 0.085494], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 91 / 168], [train main loss 0.084761], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 92 / 168], [train main loss 0.084419], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 93 / 168], [train main loss 0.083853], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 94 / 168], [train main loss 0.083580], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 95 / 168], [train main loss 0.083668], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 96 / 168], [train main loss 0.083397], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 97 / 168], [train main loss 0.082960], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 98 / 168], [train main loss 0.083353], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 99 / 168], [train main loss 0.083586], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 100 / 168], [train main loss 0.083209], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 101 / 168], [train main loss 0.083569], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 102 / 168], [train main loss 0.083208], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 103 / 168], [train main loss 0.083255], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 104 / 168], [train main loss 0.083230], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 105 / 168], [train main loss 0.083231], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 106 / 168], [train main loss 0.083066], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 107 / 168], [train main loss 0.083692], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 108 / 168], [train main loss 0.083336], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 109 / 168], [train main loss 0.083361], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 110 / 168], [train main loss 0.083133], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 111 / 168], [train main loss 0.083306], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 112 / 168], [train main loss 0.083718], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 113 / 168], [train main loss 0.083595], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 114 / 168], [train main loss 0.083591], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 115 / 168], [train main loss 0.084747], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 116 / 168], [train main loss 0.084507], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 117 / 168], [train main loss 0.084040], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 118 / 168], [train main loss 0.084211], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 119 / 168], [train main loss 0.084192], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 120 / 168], [train main loss 0.083690], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 121 / 168], [train main loss 0.083434], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 122 / 168], [train main loss 0.083030], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 123 / 168], [train main loss 0.082589], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 124 / 168], [train main loss 0.082372], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 125 / 168], [train main loss 0.082410], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 126 / 168], [train main loss 0.082225], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 127 / 168], [train main loss 0.082209], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 128 / 168], [train main loss 0.082432], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 129 / 168], [train main loss 0.082311], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 130 / 168], [train main loss 0.082239], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 131 / 168], [train main loss 0.082265], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 132 / 168], [train main loss 0.082509], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 133 / 168], [train main loss 0.082517], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 134 / 168], [train main loss 0.082256], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 135 / 168], [train main loss 0.082463], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 136 / 168], [train main loss 0.082402], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 137 / 168], [train main loss 0.082126], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 138 / 168], [train main loss 0.081760], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 139 / 168], [train main loss 0.081498], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 140 / 168], [train main loss 0.081125], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 141 / 168], [train main loss 0.081321], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 142 / 168], [train main loss 0.080981], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 143 / 168], [train main loss 0.080846], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 144 / 168], [train main loss 0.080603], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 145 / 168], [train main loss 0.080604], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 146 / 168], [train main loss 0.080455], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 147 / 168], [train main loss 0.080185], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 148 / 168], [train main loss 0.080116], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 149 / 168], [train main loss 0.080320], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 150 / 168], [train main loss 0.080438], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 151 / 168], [train main loss 0.080055], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 152 / 168], [train main loss 0.080095], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 153 / 168], [train main loss 0.080025], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 154 / 168], [train main loss 0.080156], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 155 / 168], [train main loss 0.079865], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 156 / 168], [train main loss 0.080204], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 157 / 168], [train main loss 0.080433], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 158 / 168], [train main loss 0.080173], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 159 / 168], [train main loss 0.080218], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 160 / 168], [train main loss 0.080020], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 161 / 168], [train main loss 0.079885], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 162 / 168], [train main loss 0.080086], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 163 / 168], [train main loss 0.079853], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 164 / 168], [train main loss 0.079941], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 165 / 168], [train main loss 0.079714], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 166 / 168], [train main loss 0.079989], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 167 / 168], [train main loss 0.079662], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 32], [iter 168 / 168], [train main loss 0.079545], [lr 0.001000]\n","Training...\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 1 / 168], [train main loss 0.156228], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 2 / 168], [train main loss 0.115905], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 3 / 168], [train main loss 0.100364], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 4 / 168], [train main loss 0.088864], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 5 / 168], [train main loss 0.077651], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 6 / 168], [train main loss 0.077798], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 7 / 168], [train main loss 0.073678], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 8 / 168], [train main loss 0.066926], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 9 / 168], [train main loss 0.073090], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 10 / 168], [train main loss 0.083647], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 11 / 168], [train main loss 0.088569], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 12 / 168], [train main loss 0.087696], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 13 / 168], [train main loss 0.084851], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 14 / 168], [train main loss 0.089364], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 15 / 168], [train main loss 0.089192], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 16 / 168], [train main loss 0.087585], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 17 / 168], [train main loss 0.086906], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 18 / 168], [train main loss 0.084423], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 19 / 168], [train main loss 0.082998], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 20 / 168], [train main loss 0.079732], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 21 / 168], [train main loss 0.079000], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 22 / 168], [train main loss 0.078817], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 23 / 168], [train main loss 0.078081], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 24 / 168], [train main loss 0.076572], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 25 / 168], [train main loss 0.076390], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 26 / 168], [train main loss 0.078740], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 27 / 168], [train main loss 0.077111], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 28 / 168], [train main loss 0.077172], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 29 / 168], [train main loss 0.075594], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 30 / 168], [train main loss 0.075511], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 31 / 168], [train main loss 0.074326], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 32 / 168], [train main loss 0.074702], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 33 / 168], [train main loss 0.075973], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 34 / 168], [train main loss 0.075438], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 35 / 168], [train main loss 0.075481], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 36 / 168], [train main loss 0.075298], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 37 / 168], [train main loss 0.075378], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 38 / 168], [train main loss 0.076283], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 39 / 168], [train main loss 0.076321], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 40 / 168], [train main loss 0.076467], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 41 / 168], [train main loss 0.076487], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 42 / 168], [train main loss 0.077102], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 43 / 168], [train main loss 0.076651], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 44 / 168], [train main loss 0.075970], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 45 / 168], [train main loss 0.076846], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 46 / 168], [train main loss 0.076365], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 47 / 168], [train main loss 0.077563], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 48 / 168], [train main loss 0.078053], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 49 / 168], [train main loss 0.077086], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 50 / 168], [train main loss 0.076832], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 51 / 168], [train main loss 0.076862], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 52 / 168], [train main loss 0.077347], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 53 / 168], [train main loss 0.077607], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 54 / 168], [train main loss 0.077677], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 55 / 168], [train main loss 0.076966], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 56 / 168], [train main loss 0.077652], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 57 / 168], [train main loss 0.077655], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 58 / 168], [train main loss 0.077072], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 59 / 168], [train main loss 0.076527], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 60 / 168], [train main loss 0.078205], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 61 / 168], [train main loss 0.078738], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 62 / 168], [train main loss 0.079260], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 63 / 168], [train main loss 0.079037], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 64 / 168], [train main loss 0.079018], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 65 / 168], [train main loss 0.079886], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 66 / 168], [train main loss 0.080036], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 67 / 168], [train main loss 0.079284], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 68 / 168], [train main loss 0.079825], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 69 / 168], [train main loss 0.079412], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 70 / 168], [train main loss 0.080062], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 71 / 168], [train main loss 0.079620], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 72 / 168], [train main loss 0.080141], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 73 / 168], [train main loss 0.079832], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 74 / 168], [train main loss 0.079862], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 75 / 168], [train main loss 0.080286], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 76 / 168], [train main loss 0.079972], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 77 / 168], [train main loss 0.080511], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 78 / 168], [train main loss 0.080418], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 79 / 168], [train main loss 0.080025], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 80 / 168], [train main loss 0.079804], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 81 / 168], [train main loss 0.080534], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 82 / 168], [train main loss 0.080360], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 83 / 168], [train main loss 0.079760], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 84 / 168], [train main loss 0.081586], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 85 / 168], [train main loss 0.081922], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 86 / 168], [train main loss 0.081791], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 87 / 168], [train main loss 0.081594], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 88 / 168], [train main loss 0.080946], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 89 / 168], [train main loss 0.081025], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 90 / 168], [train main loss 0.081101], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 91 / 168], [train main loss 0.080405], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 92 / 168], [train main loss 0.080032], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 93 / 168], [train main loss 0.079519], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 94 / 168], [train main loss 0.079176], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 95 / 168], [train main loss 0.079318], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 96 / 168], [train main loss 0.079042], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 97 / 168], [train main loss 0.078679], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 98 / 168], [train main loss 0.079019], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 99 / 168], [train main loss 0.079295], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 100 / 168], [train main loss 0.078968], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 101 / 168], [train main loss 0.079174], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 102 / 168], [train main loss 0.078811], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 103 / 168], [train main loss 0.079082], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 104 / 168], [train main loss 0.079070], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 105 / 168], [train main loss 0.079120], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 106 / 168], [train main loss 0.079023], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 107 / 168], [train main loss 0.079591], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 108 / 168], [train main loss 0.079256], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 109 / 168], [train main loss 0.079323], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 110 / 168], [train main loss 0.079192], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 111 / 168], [train main loss 0.079428], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 112 / 168], [train main loss 0.079927], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 113 / 168], [train main loss 0.079900], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 114 / 168], [train main loss 0.079909], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 115 / 168], [train main loss 0.081227], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 116 / 168], [train main loss 0.081037], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 117 / 168], [train main loss 0.080591], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 118 / 168], [train main loss 0.080796], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 119 / 168], [train main loss 0.080792], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 120 / 168], [train main loss 0.080329], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 121 / 168], [train main loss 0.080042], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 122 / 168], [train main loss 0.079642], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 123 / 168], [train main loss 0.079242], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 124 / 168], [train main loss 0.078998], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 125 / 168], [train main loss 0.079100], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 126 / 168], [train main loss 0.078846], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 127 / 168], [train main loss 0.078816], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 128 / 168], [train main loss 0.079141], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 129 / 168], [train main loss 0.078979], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 130 / 168], [train main loss 0.078883], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 131 / 168], [train main loss 0.078801], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 132 / 168], [train main loss 0.079079], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 133 / 168], [train main loss 0.079042], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 134 / 168], [train main loss 0.078776], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 135 / 168], [train main loss 0.079150], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 136 / 168], [train main loss 0.079126], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 137 / 168], [train main loss 0.078869], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 138 / 168], [train main loss 0.078553], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 139 / 168], [train main loss 0.078321], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 140 / 168], [train main loss 0.077964], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 141 / 168], [train main loss 0.078249], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 142 / 168], [train main loss 0.077932], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 143 / 168], [train main loss 0.077805], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 144 / 168], [train main loss 0.077577], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 145 / 168], [train main loss 0.077680], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 146 / 168], [train main loss 0.077540], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 147 / 168], [train main loss 0.077261], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 148 / 168], [train main loss 0.077196], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 149 / 168], [train main loss 0.077424], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 150 / 168], [train main loss 0.077593], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 151 / 168], [train main loss 0.077213], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 152 / 168], [train main loss 0.077243], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 153 / 168], [train main loss 0.077197], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 154 / 168], [train main loss 0.077467], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 155 / 168], [train main loss 0.077199], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 156 / 168], [train main loss 0.077496], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 157 / 168], [train main loss 0.077761], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 158 / 168], [train main loss 0.077524], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 159 / 168], [train main loss 0.077579], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 160 / 168], [train main loss 0.077446], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 161 / 168], [train main loss 0.077347], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 162 / 168], [train main loss 0.077504], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 163 / 168], [train main loss 0.077268], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 164 / 168], [train main loss 0.077391], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 165 / 168], [train main loss 0.077176], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 166 / 168], [train main loss 0.077542], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 167 / 168], [train main loss 0.077184], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 33], [iter 168 / 168], [train main loss 0.077060], [lr 0.001000]\n","Training...\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 1 / 168], [train main loss 0.135848], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 2 / 168], [train main loss 0.105659], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 3 / 168], [train main loss 0.092213], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 4 / 168], [train main loss 0.084566], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 5 / 168], [train main loss 0.073653], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 6 / 168], [train main loss 0.074817], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 7 / 168], [train main loss 0.070481], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 8 / 168], [train main loss 0.064072], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 9 / 168], [train main loss 0.073124], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 10 / 168], [train main loss 0.090968], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 11 / 168], [train main loss 0.095401], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 12 / 168], [train main loss 0.093509], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 13 / 168], [train main loss 0.090363], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 14 / 168], [train main loss 0.094225], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 15 / 168], [train main loss 0.093934], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 16 / 168], [train main loss 0.092163], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 17 / 168], [train main loss 0.095552], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 18 / 168], [train main loss 0.092971], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 19 / 168], [train main loss 0.091132], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 20 / 168], [train main loss 0.087543], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 21 / 168], [train main loss 0.087069], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 22 / 168], [train main loss 0.086464], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 23 / 168], [train main loss 0.085951], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 24 / 168], [train main loss 0.084329], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 25 / 168], [train main loss 0.084445], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 26 / 168], [train main loss 0.087978], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 27 / 168], [train main loss 0.086243], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 28 / 168], [train main loss 0.086602], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 29 / 168], [train main loss 0.086164], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 30 / 168], [train main loss 0.085737], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 31 / 168], [train main loss 0.084339], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 32 / 168], [train main loss 0.084597], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 33 / 168], [train main loss 0.086035], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 34 / 168], [train main loss 0.085416], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 35 / 168], [train main loss 0.085740], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 36 / 168], [train main loss 0.085523], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 37 / 168], [train main loss 0.085446], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 38 / 168], [train main loss 0.087057], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 39 / 168], [train main loss 0.086847], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 40 / 168], [train main loss 0.087756], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 41 / 168], [train main loss 0.087564], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 42 / 168], [train main loss 0.088549], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 43 / 168], [train main loss 0.088312], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 44 / 168], [train main loss 0.087450], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 45 / 168], [train main loss 0.088606], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 46 / 168], [train main loss 0.088222], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 47 / 168], [train main loss 0.088949], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 48 / 168], [train main loss 0.089346], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 49 / 168], [train main loss 0.088374], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 50 / 168], [train main loss 0.087909], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 51 / 168], [train main loss 0.087916], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 52 / 168], [train main loss 0.088391], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 53 / 168], [train main loss 0.088748], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 54 / 168], [train main loss 0.088761], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 55 / 168], [train main loss 0.087878], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 56 / 168], [train main loss 0.088617], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 57 / 168], [train main loss 0.089192], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 58 / 168], [train main loss 0.088452], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 59 / 168], [train main loss 0.087803], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 60 / 168], [train main loss 0.090205], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 61 / 168], [train main loss 0.090341], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 62 / 168], [train main loss 0.090616], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 63 / 168], [train main loss 0.090332], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 64 / 168], [train main loss 0.090618], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 65 / 168], [train main loss 0.091632], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 66 / 168], [train main loss 0.092289], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 67 / 168], [train main loss 0.091345], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 68 / 168], [train main loss 0.091871], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 69 / 168], [train main loss 0.091291], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 70 / 168], [train main loss 0.091707], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 71 / 168], [train main loss 0.091370], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 72 / 168], [train main loss 0.091988], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 73 / 168], [train main loss 0.091536], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 74 / 168], [train main loss 0.091266], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 75 / 168], [train main loss 0.091436], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 76 / 168], [train main loss 0.091032], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 77 / 168], [train main loss 0.091426], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 78 / 168], [train main loss 0.091331], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 79 / 168], [train main loss 0.091194], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 80 / 168], [train main loss 0.090948], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 81 / 168], [train main loss 0.091683], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 82 / 168], [train main loss 0.091433], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 83 / 168], [train main loss 0.090807], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 84 / 168], [train main loss 0.092498], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 85 / 168], [train main loss 0.092867], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 86 / 168], [train main loss 0.092753], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 87 / 168], [train main loss 0.092511], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 88 / 168], [train main loss 0.091788], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 89 / 168], [train main loss 0.091697], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 90 / 168], [train main loss 0.091781], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 91 / 168], [train main loss 0.091020], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 92 / 168], [train main loss 0.090548], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 93 / 168], [train main loss 0.089971], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 94 / 168], [train main loss 0.089506], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 95 / 168], [train main loss 0.089844], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 96 / 168], [train main loss 0.089499], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 97 / 168], [train main loss 0.089106], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 98 / 168], [train main loss 0.089520], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 99 / 168], [train main loss 0.089717], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 100 / 168], [train main loss 0.089261], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 101 / 168], [train main loss 0.089855], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 102 / 168], [train main loss 0.089389], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 103 / 168], [train main loss 0.089292], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 104 / 168], [train main loss 0.089330], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 105 / 168], [train main loss 0.089370], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 106 / 168], [train main loss 0.089263], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 107 / 168], [train main loss 0.090064], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 108 / 168], [train main loss 0.089695], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 109 / 168], [train main loss 0.089670], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 110 / 168], [train main loss 0.089376], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 111 / 168], [train main loss 0.089703], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 112 / 168], [train main loss 0.090114], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 113 / 168], [train main loss 0.089984], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 114 / 168], [train main loss 0.089983], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 115 / 168], [train main loss 0.090980], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 116 / 168], [train main loss 0.090741], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 117 / 168], [train main loss 0.090229], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 118 / 168], [train main loss 0.090283], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 119 / 168], [train main loss 0.090236], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 120 / 168], [train main loss 0.089681], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 121 / 168], [train main loss 0.089407], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 122 / 168], [train main loss 0.088976], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 123 / 168], [train main loss 0.088514], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 124 / 168], [train main loss 0.088268], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 125 / 168], [train main loss 0.088231], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 126 / 168], [train main loss 0.087910], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 127 / 168], [train main loss 0.087856], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 128 / 168], [train main loss 0.088035], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 129 / 168], [train main loss 0.087861], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 130 / 168], [train main loss 0.087743], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 131 / 168], [train main loss 0.087833], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 132 / 168], [train main loss 0.088048], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 133 / 168], [train main loss 0.087960], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 134 / 168], [train main loss 0.087641], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 135 / 168], [train main loss 0.087911], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 136 / 168], [train main loss 0.087829], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 137 / 168], [train main loss 0.087522], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 138 / 168], [train main loss 0.087159], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 139 / 168], [train main loss 0.086858], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 140 / 168], [train main loss 0.086445], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 141 / 168], [train main loss 0.086568], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 142 / 168], [train main loss 0.086195], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 143 / 168], [train main loss 0.085984], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 144 / 168], [train main loss 0.085672], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 145 / 168], [train main loss 0.085662], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 146 / 168], [train main loss 0.085460], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 147 / 168], [train main loss 0.085132], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 148 / 168], [train main loss 0.084953], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 149 / 168], [train main loss 0.085182], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 150 / 168], [train main loss 0.085329], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 151 / 168], [train main loss 0.084896], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 152 / 168], [train main loss 0.084870], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 153 / 168], [train main loss 0.084849], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 154 / 168], [train main loss 0.084952], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 155 / 168], [train main loss 0.084624], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 156 / 168], [train main loss 0.084898], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 157 / 168], [train main loss 0.085101], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 158 / 168], [train main loss 0.084828], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 159 / 168], [train main loss 0.084841], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 160 / 168], [train main loss 0.084604], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 161 / 168], [train main loss 0.084429], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 162 / 168], [train main loss 0.084587], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 163 / 168], [train main loss 0.084309], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 164 / 168], [train main loss 0.084344], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 165 / 168], [train main loss 0.084084], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 166 / 168], [train main loss 0.084346], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 167 / 168], [train main loss 0.083970], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 34], [iter 168 / 168], [train main loss 0.083842], [lr 0.001000]\n","Training...\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 1 / 168], [train main loss 0.134756], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 2 / 168], [train main loss 0.103814], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 3 / 168], [train main loss 0.090995], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 4 / 168], [train main loss 0.082799], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 5 / 168], [train main loss 0.072699], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 6 / 168], [train main loss 0.074238], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 7 / 168], [train main loss 0.070403], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 8 / 168], [train main loss 0.064092], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 9 / 168], [train main loss 0.071098], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 10 / 168], [train main loss 0.083040], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 11 / 168], [train main loss 0.088274], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 12 / 168], [train main loss 0.087331], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 13 / 168], [train main loss 0.084823], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 14 / 168], [train main loss 0.094074], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 15 / 168], [train main loss 0.092949], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 16 / 168], [train main loss 0.092837], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 17 / 168], [train main loss 0.092598], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 18 / 168], [train main loss 0.093046], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 19 / 168], [train main loss 0.093425], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 20 / 168], [train main loss 0.090114], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 21 / 168], [train main loss 0.090188], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 22 / 168], [train main loss 0.090965], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 23 / 168], [train main loss 0.090872], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 24 / 168], [train main loss 0.089904], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 25 / 168], [train main loss 0.090661], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 26 / 168], [train main loss 0.102961], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 27 / 168], [train main loss 0.102225], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 28 / 168], [train main loss 0.102787], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 29 / 168], [train main loss 0.102330], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 30 / 168], [train main loss 0.107622], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 31 / 168], [train main loss 0.106529], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 32 / 168], [train main loss 0.107854], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 33 / 168], [train main loss 0.110462], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 34 / 168], [train main loss 0.109344], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 35 / 168], [train main loss 0.122024], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 36 / 168], [train main loss 0.121774], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 37 / 168], [train main loss 0.121695], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 38 / 168], [train main loss 0.125572], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 39 / 168], [train main loss 0.128298], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 40 / 168], [train main loss 0.128948], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 41 / 168], [train main loss 0.128994], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 42 / 168], [train main loss 0.130256], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 43 / 168], [train main loss 0.134000], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 44 / 168], [train main loss 0.134413], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 45 / 168], [train main loss 0.137006], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 46 / 168], [train main loss 0.137278], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 47 / 168], [train main loss 0.139517], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 48 / 168], [train main loss 0.140572], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 49 / 168], [train main loss 0.139308], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 50 / 168], [train main loss 0.138145], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 51 / 168], [train main loss 0.138325], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 52 / 168], [train main loss 0.138612], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 53 / 168], [train main loss 0.138932], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 54 / 168], [train main loss 0.138899], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 55 / 168], [train main loss 0.137861], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 56 / 168], [train main loss 0.138588], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 57 / 168], [train main loss 0.138950], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 58 / 168], [train main loss 0.137857], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 59 / 168], [train main loss 0.136527], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 60 / 168], [train main loss 0.139475], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 61 / 168], [train main loss 0.139168], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 62 / 168], [train main loss 0.139290], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 63 / 168], [train main loss 0.138322], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 64 / 168], [train main loss 0.139097], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 65 / 168], [train main loss 0.139746], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 66 / 168], [train main loss 0.140184], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 67 / 168], [train main loss 0.138962], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 68 / 168], [train main loss 0.139537], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 69 / 168], [train main loss 0.138543], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 70 / 168], [train main loss 0.139877], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 71 / 168], [train main loss 0.139056], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 72 / 168], [train main loss 0.139949], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 73 / 168], [train main loss 0.139029], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 74 / 168], [train main loss 0.138896], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 75 / 168], [train main loss 0.138728], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 76 / 168], [train main loss 0.137966], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 77 / 168], [train main loss 0.138587], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 78 / 168], [train main loss 0.138077], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 79 / 168], [train main loss 0.138604], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 80 / 168], [train main loss 0.137973], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 81 / 168], [train main loss 0.138453], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 82 / 168], [train main loss 0.137835], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 83 / 168], [train main loss 0.136817], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 84 / 168], [train main loss 0.137994], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 85 / 168], [train main loss 0.138178], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 86 / 168], [train main loss 0.137719], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 87 / 168], [train main loss 0.137356], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 88 / 168], [train main loss 0.136326], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 89 / 168], [train main loss 0.136316], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 90 / 168], [train main loss 0.135989], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 91 / 168], [train main loss 0.134820], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 92 / 168], [train main loss 0.133914], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 93 / 168], [train main loss 0.132897], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 94 / 168], [train main loss 0.132176], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 95 / 168], [train main loss 0.132095], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 96 / 168], [train main loss 0.131625], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 97 / 168], [train main loss 0.130783], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 98 / 168], [train main loss 0.131564], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 99 / 168], [train main loss 0.131820], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 100 / 168], [train main loss 0.131068], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 101 / 168], [train main loss 0.131966], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 102 / 168], [train main loss 0.131184], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 103 / 168], [train main loss 0.131075], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 104 / 168], [train main loss 0.130914], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 105 / 168], [train main loss 0.130663], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 106 / 168], [train main loss 0.130554], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 107 / 168], [train main loss 0.131043], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 108 / 168], [train main loss 0.130351], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 109 / 168], [train main loss 0.130134], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 110 / 168], [train main loss 0.129619], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 111 / 168], [train main loss 0.130190], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 112 / 168], [train main loss 0.130326], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 113 / 168], [train main loss 0.130238], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 114 / 168], [train main loss 0.130057], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 115 / 168], [train main loss 0.131421], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 116 / 168], [train main loss 0.131015], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 117 / 168], [train main loss 0.130258], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 118 / 168], [train main loss 0.130153], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 119 / 168], [train main loss 0.130007], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 120 / 168], [train main loss 0.129233], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 121 / 168], [train main loss 0.128640], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 122 / 168], [train main loss 0.127940], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 123 / 168], [train main loss 0.127200], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 124 / 168], [train main loss 0.126690], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 125 / 168], [train main loss 0.126407], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 126 / 168], [train main loss 0.125917], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 127 / 168], [train main loss 0.125595], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 128 / 168], [train main loss 0.125754], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 129 / 168], [train main loss 0.125291], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 130 / 168], [train main loss 0.124953], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 131 / 168], [train main loss 0.124934], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 132 / 168], [train main loss 0.125040], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 133 / 168], [train main loss 0.124709], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 134 / 168], [train main loss 0.124150], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 135 / 168], [train main loss 0.124716], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 136 / 168], [train main loss 0.124384], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 137 / 168], [train main loss 0.123826], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 138 / 168], [train main loss 0.123226], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 139 / 168], [train main loss 0.122746], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 140 / 168], [train main loss 0.122098], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 141 / 168], [train main loss 0.122021], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 142 / 168], [train main loss 0.121414], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 143 / 168], [train main loss 0.120993], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 144 / 168], [train main loss 0.120512], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 145 / 168], [train main loss 0.120434], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 146 / 168], [train main loss 0.120057], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 147 / 168], [train main loss 0.119543], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 148 / 168], [train main loss 0.119314], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 149 / 168], [train main loss 0.119415], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 150 / 168], [train main loss 0.119425], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 151 / 168], [train main loss 0.118776], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 152 / 168], [train main loss 0.118833], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 153 / 168], [train main loss 0.118644], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 154 / 168], [train main loss 0.118792], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 155 / 168], [train main loss 0.118330], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 156 / 168], [train main loss 0.118582], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 157 / 168], [train main loss 0.118818], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 158 / 168], [train main loss 0.118383], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 159 / 168], [train main loss 0.118377], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 160 / 168], [train main loss 0.118108], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 161 / 168], [train main loss 0.117728], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 162 / 168], [train main loss 0.117760], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 163 / 168], [train main loss 0.117290], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 164 / 168], [train main loss 0.117171], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 165 / 168], [train main loss 0.116731], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 166 / 168], [train main loss 0.117200], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 167 / 168], [train main loss 0.116648], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 35], [iter 168 / 168], [train main loss 0.116464], [lr 0.001000]\n","Training...\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 1 / 168], [train main loss 0.156965], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 2 / 168], [train main loss 0.118918], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 3 / 168], [train main loss 0.104995], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 4 / 168], [train main loss 0.098713], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 5 / 168], [train main loss 0.086355], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 6 / 168], [train main loss 0.090842], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 7 / 168], [train main loss 0.085281], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 8 / 168], [train main loss 0.077423], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 9 / 168], [train main loss 0.084188], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 10 / 168], [train main loss 0.097911], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 11 / 168], [train main loss 0.105620], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 12 / 168], [train main loss 0.106603], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 13 / 168], [train main loss 0.102845], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 14 / 168], [train main loss 0.110215], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 15 / 168], [train main loss 0.108665], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 16 / 168], [train main loss 0.107194], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 17 / 168], [train main loss 0.105651], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 18 / 168], [train main loss 0.103907], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 19 / 168], [train main loss 0.102294], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 20 / 168], [train main loss 0.098285], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 21 / 168], [train main loss 0.099510], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 22 / 168], [train main loss 0.098385], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 23 / 168], [train main loss 0.097114], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 24 / 168], [train main loss 0.095048], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 25 / 168], [train main loss 0.094672], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 26 / 168], [train main loss 0.099039], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 27 / 168], [train main loss 0.096998], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 28 / 168], [train main loss 0.096814], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 29 / 168], [train main loss 0.094858], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 30 / 168], [train main loss 0.094863], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 31 / 168], [train main loss 0.093318], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 32 / 168], [train main loss 0.093378], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 33 / 168], [train main loss 0.094755], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 34 / 168], [train main loss 0.093834], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 35 / 168], [train main loss 0.093812], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 36 / 168], [train main loss 0.093712], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 37 / 168], [train main loss 0.093476], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 38 / 168], [train main loss 0.095210], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 39 / 168], [train main loss 0.095027], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 40 / 168], [train main loss 0.095128], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 41 / 168], [train main loss 0.094873], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 42 / 168], [train main loss 0.095359], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 43 / 168], [train main loss 0.094785], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 44 / 168], [train main loss 0.094235], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 45 / 168], [train main loss 0.094995], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 46 / 168], [train main loss 0.094425], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 47 / 168], [train main loss 0.096140], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 48 / 168], [train main loss 0.096365], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 49 / 168], [train main loss 0.095080], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 50 / 168], [train main loss 0.094743], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 51 / 168], [train main loss 0.094922], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 52 / 168], [train main loss 0.095286], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 53 / 168], [train main loss 0.095360], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 54 / 168], [train main loss 0.095348], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 55 / 168], [train main loss 0.094394], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 56 / 168], [train main loss 0.094996], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 57 / 168], [train main loss 0.094748], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 58 / 168], [train main loss 0.093976], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 59 / 168], [train main loss 0.093198], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 60 / 168], [train main loss 0.095768], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 61 / 168], [train main loss 0.096391], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 62 / 168], [train main loss 0.097003], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 63 / 168], [train main loss 0.096580], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 64 / 168], [train main loss 0.096501], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 65 / 168], [train main loss 0.097468], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 66 / 168], [train main loss 0.097540], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 67 / 168], [train main loss 0.096556], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 68 / 168], [train main loss 0.097202], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 69 / 168], [train main loss 0.096620], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 70 / 168], [train main loss 0.097302], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 71 / 168], [train main loss 0.096731], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 72 / 168], [train main loss 0.097587], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 73 / 168], [train main loss 0.097249], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 74 / 168], [train main loss 0.096996], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 75 / 168], [train main loss 0.097111], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 76 / 168], [train main loss 0.096653], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 77 / 168], [train main loss 0.097212], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 78 / 168], [train main loss 0.096966], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 79 / 168], [train main loss 0.096528], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 80 / 168], [train main loss 0.096216], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 81 / 168], [train main loss 0.096931], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 82 / 168], [train main loss 0.096675], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 83 / 168], [train main loss 0.095923], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 84 / 168], [train main loss 0.097670], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 85 / 168], [train main loss 0.097898], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 86 / 168], [train main loss 0.097689], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 87 / 168], [train main loss 0.097464], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 88 / 168], [train main loss 0.096682], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 89 / 168], [train main loss 0.096512], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 90 / 168], [train main loss 0.096675], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 91 / 168], [train main loss 0.095854], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 92 / 168], [train main loss 0.095313], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 93 / 168], [train main loss 0.094716], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 94 / 168], [train main loss 0.094261], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 95 / 168], [train main loss 0.094333], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 96 / 168], [train main loss 0.093986], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 97 / 168], [train main loss 0.093708], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 98 / 168], [train main loss 0.094070], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 99 / 168], [train main loss 0.094277], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 100 / 168], [train main loss 0.093836], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 101 / 168], [train main loss 0.094409], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 102 / 168], [train main loss 0.093901], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 103 / 168], [train main loss 0.093801], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 104 / 168], [train main loss 0.093761], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 105 / 168], [train main loss 0.093817], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 106 / 168], [train main loss 0.093825], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 107 / 168], [train main loss 0.094707], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 108 / 168], [train main loss 0.094257], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 109 / 168], [train main loss 0.094239], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 110 / 168], [train main loss 0.093938], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 111 / 168], [train main loss 0.094335], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 112 / 168], [train main loss 0.094670], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 113 / 168], [train main loss 0.094721], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 114 / 168], [train main loss 0.094679], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 115 / 168], [train main loss 0.096401], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 116 / 168], [train main loss 0.096210], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 117 / 168], [train main loss 0.095638], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 118 / 168], [train main loss 0.095753], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 119 / 168], [train main loss 0.095704], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 120 / 168], [train main loss 0.095119], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 121 / 168], [train main loss 0.094769], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 122 / 168], [train main loss 0.094331], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 123 / 168], [train main loss 0.093815], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 124 / 168], [train main loss 0.093535], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 125 / 168], [train main loss 0.093384], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 126 / 168], [train main loss 0.093206], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 127 / 168], [train main loss 0.093054], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 128 / 168], [train main loss 0.093370], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 129 / 168], [train main loss 0.093199], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 130 / 168], [train main loss 0.093051], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 131 / 168], [train main loss 0.093165], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 132 / 168], [train main loss 0.093401], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 133 / 168], [train main loss 0.093293], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 134 / 168], [train main loss 0.093015], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 135 / 168], [train main loss 0.093534], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 136 / 168], [train main loss 0.093439], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 137 / 168], [train main loss 0.093214], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 138 / 168], [train main loss 0.092842], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 139 / 168], [train main loss 0.092591], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 140 / 168], [train main loss 0.092174], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 141 / 168], [train main loss 0.092215], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 142 / 168], [train main loss 0.091830], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 143 / 168], [train main loss 0.091611], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 144 / 168], [train main loss 0.091285], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 145 / 168], [train main loss 0.091326], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 146 / 168], [train main loss 0.091108], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 147 / 168], [train main loss 0.090769], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 148 / 168], [train main loss 0.090590], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 149 / 168], [train main loss 0.090795], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 150 / 168], [train main loss 0.091005], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 151 / 168], [train main loss 0.090523], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 152 / 168], [train main loss 0.090552], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 153 / 168], [train main loss 0.090445], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 154 / 168], [train main loss 0.090618], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 155 / 168], [train main loss 0.090292], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 156 / 168], [train main loss 0.090674], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 157 / 168], [train main loss 0.090947], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 158 / 168], [train main loss 0.090656], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 159 / 168], [train main loss 0.090628], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 160 / 168], [train main loss 0.090435], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 161 / 168], [train main loss 0.090218], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 162 / 168], [train main loss 0.090390], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 163 / 168], [train main loss 0.090088], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 164 / 168], [train main loss 0.090121], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 165 / 168], [train main loss 0.089835], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 166 / 168], [train main loss 0.090264], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 167 / 168], [train main loss 0.089899], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 36], [iter 168 / 168], [train main loss 0.089757], [lr 0.001000]\n","Training...\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 1 / 168], [train main loss 0.142393], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 2 / 168], [train main loss 0.109606], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 3 / 168], [train main loss 0.096263], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 4 / 168], [train main loss 0.088838], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 5 / 168], [train main loss 0.077559], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 6 / 168], [train main loss 0.079956], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 7 / 168], [train main loss 0.075440], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 8 / 168], [train main loss 0.068907], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 9 / 168], [train main loss 0.075894], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 10 / 168], [train main loss 0.088939], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 11 / 168], [train main loss 0.095459], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 12 / 168], [train main loss 0.093657], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 13 / 168], [train main loss 0.090565], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 14 / 168], [train main loss 0.095272], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 15 / 168], [train main loss 0.094184], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 16 / 168], [train main loss 0.092404], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 17 / 168], [train main loss 0.091092], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 18 / 168], [train main loss 0.088723], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 19 / 168], [train main loss 0.087322], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 20 / 168], [train main loss 0.083781], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 21 / 168], [train main loss 0.083860], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 22 / 168], [train main loss 0.082729], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 23 / 168], [train main loss 0.082099], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 24 / 168], [train main loss 0.080737], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 25 / 168], [train main loss 0.081605], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 26 / 168], [train main loss 0.084472], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 27 / 168], [train main loss 0.082684], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 28 / 168], [train main loss 0.082959], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 29 / 168], [train main loss 0.081291], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 30 / 168], [train main loss 0.081334], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 31 / 168], [train main loss 0.080037], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 32 / 168], [train main loss 0.080374], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 33 / 168], [train main loss 0.082191], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 34 / 168], [train main loss 0.081444], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 35 / 168], [train main loss 0.081479], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 36 / 168], [train main loss 0.081666], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 37 / 168], [train main loss 0.081607], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 38 / 168], [train main loss 0.082824], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 39 / 168], [train main loss 0.082746], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 40 / 168], [train main loss 0.083048], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 41 / 168], [train main loss 0.083002], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 42 / 168], [train main loss 0.083961], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 43 / 168], [train main loss 0.083461], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 44 / 168], [train main loss 0.083047], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 45 / 168], [train main loss 0.083778], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 46 / 168], [train main loss 0.083345], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 47 / 168], [train main loss 0.084997], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 48 / 168], [train main loss 0.085235], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 49 / 168], [train main loss 0.084112], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 50 / 168], [train main loss 0.083748], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 51 / 168], [train main loss 0.083955], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 52 / 168], [train main loss 0.084426], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 53 / 168], [train main loss 0.084673], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 54 / 168], [train main loss 0.084598], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 55 / 168], [train main loss 0.083825], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 56 / 168], [train main loss 0.084615], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 57 / 168], [train main loss 0.084539], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 58 / 168], [train main loss 0.083842], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 59 / 168], [train main loss 0.083235], [lr 0.001000]\n","Loading...\n","\n","\n","\n","[epoch 37], [iter 60 / 168], [train main loss 0.084953], [lr 0.001000]\n","Loading...\n","\n","\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-84528147555c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m   \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-a0cae2faab7c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, net, optim, curr_epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtrain_main_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_main_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pixel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mmain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2M9O5u_h06I7","executionInfo":{"status":"ok","timestamp":1620425850362,"user_tz":-480,"elapsed":632494,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}},"outputId":"f7040b77-5803-4c24-a813-7eea47ba0c4d"},"source":["msg = ('[accuracy {:0.2f}]')\n","accuracy_score = dice_score_dataset(net, train_dataloader, 2)\n","msg = msg.format(accuracy_score)\n","print(msg)"],"execution_count":61,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[accuracy 0.00]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_VzmQqI7cinF"},"source":["# **Save the model**"]},{"cell_type":"code","metadata":{"id":"H3_DPRfWHOpg","executionInfo":{"status":"ok","timestamp":1620424425391,"user_tz":-480,"elapsed":2518,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["torch.save(net, '/content/drive/MyDrive/Colab Notebooks/project/model_trained.pth')"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"24didZZ3HFef"},"source":["# **Visualize results**"]},{"cell_type":"code","metadata":{"id":"220qU2yzVFA7","executionInfo":{"status":"ok","timestamp":1620426668750,"user_tz":-480,"elapsed":868,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}}},"source":["train_dataset = ImageDataset(input_dir=data_dir, op=\"train\",mask_json_path=mask_json)\n","train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n","for i, data in enumerate(train_dataloader):\n","  images, gts = data\n","  if i == 4:\n","      input_save = images.cuda()\n","      gts_save = gts.cuda()\n","      break\n","\n","# test_dataset = ImageDataset(input_dir=data_dir, op=\"test\",mask_json_path=mask_json)\n","# test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n","# for i, data in enumerate(test_dataloader):\n","#   images, gts = data\n","#   if i == 4:\n","#       input_save = images.cuda()\n","#       gts_save = gts.cuda()\n","#       break"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMp6hcgvd4JB","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"ok","timestamp":1620426670583,"user_tz":-480,"elapsed":1293,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}},"outputId":"580cb33b-1947-4e50-c3ce-c20432bd48cf"},"source":["import matplotlib.pyplot as plt\n","inputs = {'images': input_save, 'gts': gts_save}\n","# model output\n","print(input_save.shape)\n","print(gts_save.shape)\n","torch.cuda.empty_cache()\n","loss, output = net(inputs)\n","pred1 = torch.argmax(output, dim=1)\n","pic = pred1[0] /5 * 255 \n","pic = pic.cpu().numpy().astype(np.uint8)\n","plt.imshow(pic, cmap=plt.cm.gray)\n"],"execution_count":68,"outputs":[{"output_type":"stream","text":["torch.Size([1, 4, 256, 256])\n","torch.Size([1, 2, 256, 256])\n","\n","\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f0e9a87df50>"]},"metadata":{"tags":[]},"execution_count":68},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"Df8QykqZhXpI","executionInfo":{"status":"ok","timestamp":1620426673282,"user_tz":-480,"elapsed":955,"user":{"displayName":"Xuhua Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbcGQKGiuY_cg5Hq8FmG1sodngJVds2D3BF8i4=s64","userId":"18014282893132657493"}},"outputId":"e9d15169-e632-4065-f6ec-b5d7289c3086"},"source":["# gts \n","pred1 = torch.argmax(gts_save, dim=1)\n","pic =  pred1[0] / 5 * 255\n","plt.imshow(pic.cpu().numpy(), cmap=plt.cm.gray)"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f0e9a7ea790>"]},"metadata":{"tags":[]},"execution_count":69},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}